{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook focuses on preparing the CIFAR-10 dataset for training a Convolutional Neural Network (CNN). The preprocessing steps include normalization, dataset splitting into training, validation, and test sets, and data augmentation to improve model generalization. The processed data is then saved for efficient reuse during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (50000, 32, 32, 3) (50000, 1)\n",
      "Test set shape: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Pixel Values\n",
    "Converts pixel values from [0, 255] to [0, 1] for better neural network performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Data into Training and Validation Sets\n",
    "Split the dataset into:\n",
    " - 66,6% train set\n",
    " - 16,6% validation set\n",
    " - 16,6% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40000, 32, 32, 3) (40000, 1)\n",
      "Validation data shape: (10000, 32, 32, 3) (10000, 1)\n",
      "Testing data shape: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for Training Set\n",
    "Data augmentation helps increase dataset diversity and reduces overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encode the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels converted to One-Hot Encoding\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Labels converted to One-Hot Encoding\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Preprocessed files saved in 'data/processed/'.\n"
     ]
    }
   ],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_data_dir = os.path.join(project_root, \"data\", \"processed\")\n",
    "train_dir = os.path.join(processed_data_dir, \"train/\")\n",
    "val_dir = os.path.join(processed_data_dir, \"val/\")\n",
    "test_dir = os.path.join(processed_data_dir, \"test/\")\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "np.save(os.path.join(train_dir, 'x_train.npy'), X_train)\n",
    "np.save(os.path.join(train_dir, 'y_train.npy'), y_train)\n",
    "\n",
    "np.save(os.path.join(val_dir, 'x_val.npy'), X_val)\n",
    "np.save(os.path.join(val_dir, 'y_val.npy'), y_val)\n",
    "\n",
    "np.save(os.path.join(test_dir, 'x_test.npy'), X_test)\n",
    "np.save(os.path.join(test_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "print(\"Data preprocessing complete. Preprocessed files saved in 'data/processed/'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
